# -*- coding: utf-8 -*-
"""sentimentos carnais

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k_aVjChIVFu7fx_R4tNLKNDMsMTsE8zD
"""

import pandas as pd
import torch
import numpy as np
from torch.utils.data import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from sklearn.metrics import f1_score, accuracy_score

"""# 1. Configurações"""

MODEL_NAME = "neuralmind/bert-base-portuguese-cased"
MAX_LEN = 128
BATCH_SIZE = 16
EPOCHS = 3
LEARNING_RATE = 2e-5

TRAIN_PATH = '/content/drive/MyDrive/ai-dataset/train.csv'
DEV_PATH = '/content/drive/MyDrive/ai-dataset/dev.csv'
TEST_PATH = '/content/drive/MyDrive/ai-dataset/test.csv'

"""# 2. Preparando e Iniciando dados"""

label_cols = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']

def load_labeled_data(path):
    df = pd.read_csv(path)

    df['labels'] = df[label_cols].values.tolist() # Lista de valores para labels
    return df

# Carregar Treino e Validação
train_df = load_labeled_data(TRAIN_PATH)
val_df = load_labeled_data(DEV_PATH)

# Carregar Teste
test_df = pd.read_csv(TEST_PATH)
# Cria colunas "falsas" com 0 para o código não quebrar
for col in label_cols:
    test_df[col] = 0.0
test_df['labels'] = test_df[label_cols].values.tolist()

# Depuração
print(f"Exemplo de dados:\n{train_df[['text', 'labels']].head(2)}")

"""# 3. Criando a Classe"""

class EmotionDataset(Dataset):
    def __init__(self, dataframe, tokenizer, max_len):
        self.tokenizer = tokenizer
        self.data = dataframe
        self.text = dataframe.text
        self.targets = dataframe.labels
        self.max_len = max_len

    def __len__(self):
        return len(self.text)

    def __getitem__(self, index):
        text = str(self.text[index])
        text = " ".join(text.split())

        inputs = self.tokenizer.encode_plus(
            text,
            None,
            add_special_tokens=True,
            max_length=self.max_len, # Agora vai funcionar
            padding='max_length',
            return_token_type_ids=True,
            truncation=True
        )

        return {
            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),
            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),
            'labels': torch.tensor(self.targets[index], dtype=torch.float)
        }

"""# 4. Tokenizando"""

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

training_set = EmotionDataset(train_df, tokenizer, MAX_LEN)
validation_set = EmotionDataset(val_df, tokenizer, MAX_LEN)
testing_set = EmotionDataset(test_df, tokenizer, MAX_LEN)

"""# 5. Modelo"""

model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=len(label_cols),
    problem_type="multi_label_classification"
)

"""# 6. Argumentos de Treinamento & Treinamento"""

training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=LEARNING_RATE,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=EPOCHS,
    weight_decay=0.01,
    eval_strategy="epoch",  # <--- CORREÇÃO: evaluation_strategy mudou para eval_strategy
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1_micro"
)

def compute_metrics(p):
    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions
    sigmoid = torch.nn.Sigmoid()
    probs = sigmoid(torch.Tensor(preds))
    y_pred = np.zeros(probs.shape)
    y_pred[probs >= 0.5] = 1
    y_true = p.label_ids
    return {'f1_micro': f1_score(y_true, y_pred, average='micro'),
            'accuracy': accuracy_score(y_true, y_pred)}

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=training_set,
    eval_dataset=validation_set,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

print("Iniciando treinamento...")
trainer.train()

"""# 9. Avaliando"""

results = trainer.evaluate(testing_set)
print(results)

"""# 10. Salvando Modelo"""

model.save_pretrained("./modelo_analise_sentimento")
tokenizer.save_pretrained("./modelo_analise_sentimento")